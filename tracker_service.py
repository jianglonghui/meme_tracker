"""
ä»£å¸è·Ÿè¸ªæœåŠ¡ (ç«¯å£ 5052)
- ä¿å­˜åŒ¹é…è®°å½•
- è¿½è¸ª 1/5/10 åˆ†é’Ÿå¸‚å€¼å˜åŒ–
- è¯„åˆ†å¹¶è®°å½•æœ€ä½³ä»£å¸
"""
import sqlite3
import threading
import time
import json
import requests
from flask import Flask, request, jsonify
import config

app = Flask(__name__)

# çŠ¶æ€ç»Ÿè®¡
stats = {
    'total_matches': 0,
    'total_tracked': 0,
    'running': True,
    'last_track': None,
    'errors': 0
}

# è¿½è¸ªä»»åŠ¡é˜Ÿåˆ—
tracking_tasks = []
tracking_lock = threading.Lock()

# é”™è¯¯æ—¥å¿—
MAX_LOG_SIZE = 50
recent_errors = []
log_lock = threading.Lock()

def log_error(msg):
    """è®°å½•é”™è¯¯"""
    with log_lock:
        recent_errors.append({'time': time.time(), 'msg': msg})
        if len(recent_errors) > MAX_LOG_SIZE:
            recent_errors.pop(0)
    stats['errors'] += 1

# å†…å­˜ä¸­çš„è¿½è¸ªæ•°æ®ï¼ˆè¿½è¸ªå®Œæˆåæ‰å†³å®šæ˜¯å¦å†™å…¥æ•°æ®åº“ï¼‰
# key: match_id (ä¸´æ—¶ID), value: {news_data, keywords, tokens, tracking_data}
pending_records = {}
pending_lock = threading.Lock()
temp_match_id = 0

# é”™è¯¯ç : -1=æ— äº¤æ˜“å¯¹, -2=HTTPé”™è¯¯, -3=ç½‘ç»œå¼‚å¸¸


def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    conn = sqlite3.connect(config.DB_PATH)
    cursor = conn.cursor()

    cursor.execute('''
        CREATE TABLE IF NOT EXISTS match_records (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            news_time INTEGER, news_author TEXT, news_author_name TEXT,
            news_avatar TEXT, news_type TEXT, news_content TEXT,
            news_images TEXT, news_videos TEXT,
            ref_author TEXT, ref_author_name TEXT, ref_avatar TEXT,
            ref_content TEXT, ref_images TEXT,
            keywords TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')

    # å…¼å®¹æ—§è¡¨ï¼šæ·»åŠ æ–°å­—æ®µ
    new_columns = [
        ('news_author_name', 'TEXT'), ('news_avatar', 'TEXT'),
        ('news_images', 'TEXT'), ('news_videos', 'TEXT'),
        ('ref_author', 'TEXT'), ('ref_author_name', 'TEXT'),
        ('ref_avatar', 'TEXT'), ('ref_content', 'TEXT'), ('ref_images', 'TEXT')
    ]
    for col, col_type in new_columns:
        try:
            cursor.execute(f'ALTER TABLE match_records ADD COLUMN {col} {col_type}')
        except:
            pass

    cursor.execute('''
        CREATE TABLE IF NOT EXISTS matched_tokens (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            match_id INTEGER, rank INTEGER,
            token_address TEXT, token_symbol TEXT, token_name TEXT, chain TEXT,
            initial_price TEXT, initial_market_cap REAL, initial_holders INTEGER,
            match_score REAL, match_keyword TEXT, match_type TEXT, final_score REAL,
            source TEXT DEFAULT 'new',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (match_id) REFERENCES match_records(id)
        )
    ''')

    # å…¼å®¹æ—§è¡¨ï¼šæ·»åŠ  source å­—æ®µ
    try:
        cursor.execute('ALTER TABLE matched_tokens ADD COLUMN source TEXT DEFAULT "new"')
    except:
        pass

    # å…¼å®¹æ—§è¡¨ï¼šæ·»åŠ  match_method å­—æ®µï¼ˆç¡¬ç¼–ç /AIï¼‰
    try:
        cursor.execute('ALTER TABLE matched_tokens ADD COLUMN match_method TEXT DEFAULT "hardcoded"')
    except:
        pass

    # å…¼å®¹æ—§è¡¨ï¼šæ·»åŠ  match_time_cost å­—æ®µï¼ˆåŒ¹é…è€—æ—¶ï¼Œæ¯«ç§’ï¼‰
    try:
        cursor.execute('ALTER TABLE matched_tokens ADD COLUMN match_time_cost INTEGER DEFAULT 0')
    except:
        pass

    # å…¼å®¹æ—§è¡¨ï¼šæ·»åŠ  is_best å­—æ®µï¼ˆæ˜¯å¦æœ€ä½³ä»£å¸ï¼‰
    try:
        cursor.execute('ALTER TABLE matched_tokens ADD COLUMN is_best INTEGER DEFAULT 0')
    except:
        pass

    # å…¼å®¹æ—§è¡¨ï¼šæ·»åŠ å„æ—¶é—´ç‚¹å¸‚å€¼å­—æ®µ
    for col in ['mcap_1min', 'mcap_5min', 'mcap_10min', 'change_1min', 'change_5min', 'change_10min']:
        try:
            cursor.execute(f'ALTER TABLE matched_tokens ADD COLUMN {col} REAL DEFAULT 0')
        except:
            pass

    cursor.execute('''
        CREATE TABLE IF NOT EXISTS market_cap_tracking (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            matched_token_id INTEGER, time_offset INTEGER,
            market_cap REAL, market_cap_change_pct REAL, price TEXT,
            tracked_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (matched_token_id) REFERENCES matched_tokens(id)
        )
    ''')

    cursor.execute('''
        CREATE TABLE IF NOT EXISTS top_performers (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            match_id INTEGER, performance_rank INTEGER,
            token_address TEXT, token_symbol TEXT, token_name TEXT, chain TEXT,
            initial_market_cap REAL, final_market_cap REAL,
            market_cap_change_pct REAL, performance_score REAL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (match_id) REFERENCES match_records(id)
        )
    ''')

    # æœ€ä½³å®è·µæ ·ä¾‹è¡¨ï¼ˆç”¨äºæç¤ºè¯ï¼‰
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS best_practices (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            tweet_content TEXT NOT NULL,
            keywords TEXT NOT NULL,
            best_token TEXT NOT NULL,
            note TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')

    # å…¨é‡æ¨æ–‡è®°å½•è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS all_news (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            news_time INTEGER,
            news_author TEXT,
            news_author_name TEXT,
            news_avatar TEXT,
            news_type TEXT,
            news_content TEXT,
            news_images TEXT,
            news_videos TEXT,
            ref_author TEXT,
            ref_author_name TEXT,
            ref_avatar TEXT,
            ref_content TEXT,
            ref_images TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')

    conn.commit()
    conn.close()
    print("[DB] æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ", flush=True)


def get_token_current_data(token_address):
    """ä» DexScreener è·å–ä»£å¸æ•°æ®ï¼Œå¤±è´¥è¿”å›é”™è¯¯ç """
    try:
        url = f"{config.DEXSCREENER_API}/{token_address}"
        resp = requests.get(url, timeout=10)
        if resp.status_code == 200:
            data = resp.json()
            pairs = data.get('pairs', [])
            if pairs:
                pair = pairs[0]
                return {
                    'market_cap': float(pair.get('marketCap') or pair.get('fdv') or 0),
                    'price': str(pair.get('priceUsd', '0')),
                }
            else:
                print(f"[DexScreener] {token_address} - æ— äº¤æ˜“å¯¹æ•°æ®", flush=True)
                return -1  # æ— äº¤æ˜“å¯¹
        else:
            print(f"[DexScreener] {token_address} - HTTP {resp.status_code}", flush=True)
            return -2  # HTTPé”™è¯¯
    except Exception as e:
        print(f"[DexScreener] {token_address} - è¯·æ±‚å¤±è´¥: {e}", flush=True)
        log_error(f"DexScreener {token_address[:10]}... è¯·æ±‚å¤±è´¥: {e}")
        return -3  # ç½‘ç»œå¼‚å¸¸
    return -1


def save_match_record(news_data, keywords, matched_tokens):
    """ä¿å­˜åŒ¹é…è®°å½•åˆ°æ•°æ®åº“ï¼Œå¼€å§‹è¿½è¸ª"""
    if not matched_tokens:
        return None

    top5 = matched_tokens[:5]

    # å†™å…¥æ•°æ®åº“
    conn = sqlite3.connect(config.DB_PATH)
    cursor = conn.cursor()

    # 1. å†™å…¥ match_records
    cursor.execute('''
        INSERT INTO match_records (
            news_time, news_author, news_author_name, news_avatar, news_type,
            news_content, news_images, news_videos,
            ref_author, ref_author_name, ref_avatar, ref_content, ref_images,
            keywords
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    ''', (
        news_data.get('time', 0),
        news_data.get('author', ''),
        news_data.get('authorName', ''),
        news_data.get('avatar', ''),
        news_data.get('type', ''),
        news_data.get('content', ''),
        json.dumps(news_data.get('images', []), ensure_ascii=False),
        json.dumps(news_data.get('videos', []), ensure_ascii=False),
        news_data.get('refAuthor', ''),
        news_data.get('refAuthorName', ''),
        news_data.get('refAvatar', ''),
        news_data.get('refContent', ''),
        json.dumps(news_data.get('refImages', []), ensure_ascii=False),
        json.dumps(keywords, ensure_ascii=False)
    ))
    db_match_id = cursor.lastrowid

    # 2. å†™å…¥ matched_tokens
    tokens_data = []
    for rank, token in enumerate(top5, 1):
        source = token.get('source', 'new')
        # è€å¸æ¥æº: binance_search, exclusive, old
        if source in ('binance_search', 'exclusive', 'old'):
            source = 'old'
        else:
            source = 'new'

        initial_mc = float(token.get('marketCap', 0) or 0)

        cursor.execute('''
            INSERT INTO matched_tokens
            (match_id, rank, token_address, token_symbol, token_name, chain,
             initial_price, initial_market_cap, initial_holders,
             match_score, match_keyword, match_type, final_score, source, match_method, match_time_cost,
             is_best, mcap_1min, mcap_5min, mcap_10min, change_1min, change_5min, change_10min)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            db_match_id, rank,
            token.get('tokenAddress', ''),
            token.get('tokenSymbol', ''),
            token.get('tokenName', ''),
            token.get('chain', 'BSC'),
            token.get('price', '0'),
            initial_mc,
            int(token.get('holders', 0) or 0),
            token.get('_match_score', 0),
            token.get('_matched_keyword', ''),
            token.get('_match_type', ''),
            0,  # final_score åˆå§‹ä¸º0
            source,
            token.get('_match_method', 'hardcoded'),
            token.get('_match_time_cost', 0),
            0, 0, 0, 0, 0, 0, 0  # is_best å’Œå¸‚å€¼å­—æ®µåˆå§‹ä¸º0
        ))
        token_db_id = cursor.lastrowid

        tokens_data.append({
            'db_id': token_db_id,
            'address': token.get('tokenAddress', ''),
            'symbol': token.get('tokenSymbol', ''),
            'initial_mc': initial_mc,
            'source': source,
            'match_keyword': token.get('_matched_keyword', ''),
            'match_type': token.get('_match_type', ''),
            'match_method': token.get('_match_method', 'hardcoded'),
            'match_time_cost': token.get('_match_time_cost', 0)
        })

    conn.commit()
    conn.close()

    # ä¿å­˜åˆ°å†…å­˜ç”¨äºè¿½è¸ª
    with pending_lock:
        pending_records[db_match_id] = {
            'news_data': news_data,
            'keywords': keywords,
            'tokens': tokens_data
        }

    stats['total_matches'] += 1
    schedule_tracking(db_match_id)
    print(f"[å†™å…¥æ•°æ®åº“] #{db_match_id} ({len(tokens_data)} ä¸ªä»£å¸)", flush=True)
    return db_match_id


def schedule_tracking(match_id):
    """å®‰æ’è¿½è¸ªä»»åŠ¡"""
    current_time = time.time()
    with tracking_lock:
        for offset in config.TRACK_INTERVALS:
            tracking_tasks.append({
                'match_id': match_id,
                'time_offset': offset,
                'execute_at': current_time + offset
            })


def track_market_cap(match_id, time_offset):
    """è¿½è¸ªå¸‚å€¼å¹¶æ›´æ–°æ•°æ®åº“"""
    with pending_lock:
        record = pending_records.get(match_id)
        if not record:
            return

    # æ—¶é—´ç‚¹å¯¹åº”çš„æ•°æ®åº“å­—æ®µ
    field_map = {
        60: ('mcap_1min', 'change_1min'),
        300: ('mcap_5min', 'change_5min'),
        600: ('mcap_10min', 'change_10min')
    }

    conn = sqlite3.connect(config.DB_PATH)
    cursor = conn.cursor()

    for token in record['tokens']:
        db_id = token['db_id']
        address = token['address']
        symbol = token['symbol']
        initial_mc = token['initial_mc']

        result = get_token_current_data(address)

        if isinstance(result, dict):
            current_mc = result['market_cap']
            change_pct = ((current_mc - initial_mc) / initial_mc * 100) if initial_mc > 0 else 0

            # æ›´æ–°æ•°æ®åº“
            if time_offset in field_map:
                mcap_field, change_field = field_map[time_offset]
                cursor.execute(f'''
                    UPDATE matched_tokens SET {mcap_field} = ?, {change_field} = ?
                    WHERE id = ?
                ''', (current_mc, change_pct, db_id))

            stats['total_tracked'] += 1
            print(f"[è¿½è¸ª] {symbol} ({time_offset}s) - MC: {current_mc:.0f} ({change_pct:+.1f}%)", flush=True)
        else:
            log_error(f"è¿½è¸ª {symbol} ({time_offset}s) å¤±è´¥: {result}")
            print(f"[è¿½è¸ª] {symbol} ({time_offset}s) - é”™è¯¯: {result}", flush=True)

    conn.commit()
    conn.close()


def calculate_performance_score(match_id):
    """
    è¿½è¸ªå®Œæˆåè®¡ç®—å¾—åˆ†å’Œæ˜¯å¦è¾¾æ ‡ï¼Œæ›´æ–°æ•°æ®åº“
    è¾¾æ ‡ä»£å¸æ ‡è®°ä¸º is_best=1ï¼š
    - æ–°å¸ï¼šå¸‚å€¼ >= 10ä¸‡
    - è€å¸ï¼šæ¶¨å¹… >= 10%
    """
    # ä»å†…å­˜è·å–å¹¶ç§»é™¤
    with pending_lock:
        record = pending_records.pop(match_id, None)

    if not record:
        return

    tokens = record['tokens']

    conn = sqlite3.connect(config.DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    best_tokens = []

    for token in tokens:
        db_id = token['db_id']
        symbol = token['symbol']
        initial_mc = token['initial_mc']
        source = token['source']

        # ä»æ•°æ®åº“è¯»å–å¸‚å€¼æ•°æ®
        cursor.execute('''
            SELECT mcap_1min, mcap_5min, mcap_10min, change_1min, change_5min, change_10min,
                   token_address, token_name, chain
            FROM matched_tokens WHERE id = ?
        ''', (db_id,))
        row = cursor.fetchone()
        if not row:
            continue

        c1 = row['change_1min'] or 0
        c5 = row['change_5min'] or 0
        c10 = row['change_10min'] or 0
        mcap_10min = row['mcap_10min'] or 0

        # è®¡ç®—å¾—åˆ†
        score = c1 * 0.2 + c5 * 0.3 + c10 * 0.5

        # åˆ¤æ–­æ˜¯å¦è¾¾æ ‡ï¼ˆå¾—åˆ†å¿…é¡»ä¸ºæ­£ï¼‰
        is_best = 0
        if score > 0:
            if source == 'old':
                if c10 >= config.MIN_CHANGE_TO_RECORD:
                    is_best = 1
                    print(f"[è¾¾æ ‡-è€å¸] {symbol} æ¶¨å¹… {c10:.1f}%", flush=True)
            else:
                if mcap_10min >= config.MIN_MCAP_TO_KEEP:
                    is_best = 1
                    print(f"[è¾¾æ ‡-æ–°å¸] {symbol} å¸‚å€¼ {mcap_10min:.0f}", flush=True)

        # æ›´æ–°æ•°æ®åº“
        cursor.execute('''
            UPDATE matched_tokens SET final_score = ?, is_best = ? WHERE id = ?
        ''', (score, is_best, db_id))

        if is_best:
            best_tokens.append({
                'db_id': db_id,
                'address': row['token_address'],
                'symbol': symbol,
                'name': row['token_name'],
                'chain': row['chain'],
                'initial_mc': initial_mc,
                'final_mc': mcap_10min,
                'change_pct': c10,
                'score': score
            })

    # å†™å…¥ top_performers
    best_tokens.sort(key=lambda x: x['score'], reverse=True)
    for rank, t in enumerate(best_tokens[:2], 1):
        cursor.execute('''
            INSERT INTO top_performers
            (match_id, performance_rank, token_address, token_symbol, token_name, chain,
             initial_market_cap, final_market_cap, market_cap_change_pct, performance_score)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (match_id, rank, t['address'], t['symbol'], t['name'],
              t['chain'], t['initial_mc'], t['final_mc'], t['change_pct'], t['score']))

    conn.commit()
    conn.close()
    print(f"[è¿½è¸ªå®Œæˆ] #{match_id} {len(best_tokens)} ä¸ªè¾¾æ ‡", flush=True)


def tracking_worker():
    """è¿½è¸ªå·¥ä½œçº¿ç¨‹"""
    print("[Tracker] è¿½è¸ªçº¿ç¨‹å¯åŠ¨", flush=True)
    while stats['running']:
        current_time = time.time()
        tasks_to_execute = []

        with tracking_lock:
            remaining = []
            for task in tracking_tasks:
                if task['execute_at'] <= current_time:
                    tasks_to_execute.append(task)
                else:
                    remaining.append(task)
            tracking_tasks[:] = remaining

        for task in tasks_to_execute:
            stats['last_track'] = time.time()
            track_market_cap(task['match_id'], task['time_offset'])
            if task['time_offset'] == 600:
                calculate_performance_score(task['match_id'])

        time.sleep(5)


def query_best_tokens(limit=10):
    """æŸ¥è¯¢æœ‰æœ€ä½³ä»£å¸çš„æ¨æ–‡è®°å½•ï¼ˆåªè¿”å›æœ‰ is_best=1 ä»£å¸çš„è®°å½•ï¼‰"""
    conn = sqlite3.connect(config.DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    # åªæŸ¥è¯¢æœ‰ is_best=1 ä»£å¸çš„è®°å½•
    cursor.execute('''
        SELECT DISTINCT m.id, m.news_time, m.news_author, m.news_author_name, m.news_avatar, m.news_type,
               m.news_content, m.news_images, m.news_videos,
               m.ref_author, m.ref_author_name, m.ref_avatar, m.ref_content, m.ref_images,
               m.keywords, m.created_at
        FROM match_records m
        INNER JOIN matched_tokens t ON m.id = t.match_id AND t.is_best = 1
        ORDER BY m.created_at DESC LIMIT ?
    ''', (limit,))
    records = cursor.fetchall()

    # è§£æ JSON å­—æ®µ
    def parse_json(val):
        if not val:
            return []
        try:
            return json.loads(val)
        except:
            return []

    results = []
    for row in records:
        mid = row['id']

        # æŸ¥è¯¢æœ€ä½³ä»£å¸ (is_best=1)
        cursor.execute('''
            SELECT token_symbol, token_name, token_address, chain,
                   initial_market_cap, final_score,
                   mcap_1min, mcap_5min, mcap_10min, change_1min, change_5min, change_10min
            FROM matched_tokens WHERE match_id = ? AND is_best = 1 ORDER BY final_score DESC
        ''', (mid,))
        best_tokens = [dict(r) for r in cursor.fetchall()]

        results.append({
            'id': mid,
            'time': row['news_time'],
            'author': row['news_author'],
            'authorName': row['news_author_name'] or '',
            'avatar': row['news_avatar'] or '',
            'type': row['news_type'],
            'content': row['news_content'],
            'images': parse_json(row['news_images']),
            'videos': parse_json(row['news_videos']),
            'refAuthor': row['ref_author'] or '',
            'refAuthorName': row['ref_author_name'] or '',
            'refAvatar': row['ref_avatar'] or '',
            'refContent': row['ref_content'] or '',
            'refImages': parse_json(row['ref_images']),
            'keywords': parse_json(row['keywords']),
            'best_tokens': best_tokens,
            'created_at': row['created_at']
        })

    conn.close()
    return results


# ==================== Flask API ====================

@app.route('/track', methods=['POST'])
def api_track():
    data = request.json
    match_id = save_match_record(data.get('news', {}), data.get('keywords', []), data.get('tokens', []))
    if match_id:
        return jsonify({'success': True, 'match_id': match_id})
    return jsonify({'success': False}), 400


@app.route('/query', methods=['GET'])
def api_query():
    limit = request.args.get('limit', 10, type=int)
    return jsonify(query_best_tokens(limit))


@app.route('/status')
def status():
    with tracking_lock:
        pending_tasks = len(tracking_tasks)
    with pending_lock:
        tracking_records = len(pending_records)
    return jsonify({
        'service': 'tracker_service',
        'port': config.TRACKER_PORT,
        'running': stats['running'],
        'total_matches': stats['total_matches'],
        'total_tracked': stats['total_tracked'],
        'pending_tasks': pending_tasks,
        'tracking_records': tracking_records,
        'last_track': stats['last_track'],
        'errors': stats['errors']
    })


@app.route('/health')
def health():
    return jsonify({'status': 'ok'})


@app.route('/recent')
def recent():
    """è¿”å›æœ€è¿‘çš„åŒ¹é…è®°å½•ï¼ˆæ•°æ®åº“ + å†…å­˜è¿½è¸ªä¸­ï¼‰"""
    # 1. å†…å­˜ä¸­æ­£åœ¨è¿½è¸ªçš„è®°å½•
    tracking = []
    with pending_lock:
        for mid, record in list(pending_records.items())[:10]:
            news = record['news_data']
            tokens = record['tokens']
            # ç»Ÿè®¡è¿½è¸ªè¿›åº¦
            track_progress = {}
            for t in tokens:
                for offset in t.get('tracking', {}).keys():
                    track_progress[offset] = track_progress.get(offset, 0) + 1

            tracking.append({
                'id': f"T{mid}",  # T è¡¨ç¤º tracking
                'time': news.get('time', 0),
                'author': news.get('author', ''),
                'content': (news.get('content', '') or '')[:50],
                'keywords': record['keywords'][:5],
                'tokens': [{
                    'symbol': t['symbol'],
                    'keyword': t['match_keyword'],
                    'match_type': t.get('match_type', ''),
                    'match_method': t.get('match_method', 'hardcoded'),
                    'match_time_cost': t.get('match_time_cost', 0),
                    'source': t.get('source', 'new')
                } for t in tokens[:3]],
                'progress': track_progress,  # {60: n, 300: n, 600: n}
                'status': 'tracking'
            })

    # 2. æ•°æ®åº“ä¸­å·²å®Œæˆçš„è®°å½•
    conn = sqlite3.connect(config.DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    cursor.execute('''
        SELECT id, news_time, news_author, news_content, keywords, created_at
        FROM match_records ORDER BY created_at DESC LIMIT 10
    ''')
    records = []
    for row in cursor.fetchall():
        mid = row['id']
        cursor.execute('''
            SELECT token_symbol, match_keyword, match_type, match_method, match_time_cost, source,
                   initial_market_cap, mcap_1min, mcap_5min, mcap_10min,
                   change_1min, change_5min, change_10min, final_score, is_best
            FROM matched_tokens
            WHERE match_id = ? ORDER BY rank
        ''', (mid,))
        tokens = [{
            'symbol': r['token_symbol'],
            'keyword': r['match_keyword'],
            'match_type': r['match_type'] or '',
            'match_method': r['match_method'] or 'hardcoded',
            'match_time_cost': r['match_time_cost'] or 0,
            'source': r['source'] or 'new',
            'initial_mcap': r['initial_market_cap'] or 0,
            'mcap_1min': r['mcap_1min'] or 0,
            'mcap_5min': r['mcap_5min'] or 0,
            'mcap_10min': r['mcap_10min'] or 0,
            'change_1min': r['change_1min'] or 0,
            'change_5min': r['change_5min'] or 0,
            'change_10min': r['change_10min'] or 0,
            'final_score': r['final_score'] or 0,
            'is_best': r['is_best'] or 0
        } for r in cursor.fetchall()]

        records.append({
            'id': mid,
            'time': row['news_time'],
            'author': row['news_author'],
            'content': row['news_content'][:50] if row['news_content'] else '',
            'keywords': json.loads(row['keywords']) if row['keywords'] else [],
            'tokens': tokens,
            'status': 'saved'
        })

    conn.close()

    # å¾…å¤„ç†ä»»åŠ¡
    with tracking_lock:
        pending = [{
            'match_id': t['match_id'],
            'time_offset': t['time_offset'],
            'execute_at': t['execute_at']
        } for t in tracking_tasks[:10]]

    # é”™è¯¯æ—¥å¿—
    with log_lock:
        errors = list(recent_errors)[::-1]

    return jsonify({'tracking': tracking, 'records': records, 'pending': pending, 'errors': errors})


# ==================== æœ€ä½³å®è·µ API ====================

@app.route('/best_practices', methods=['GET'])
def get_best_practices():
    """è·å–æœ€ä½³å®è·µæ ·ä¾‹ï¼ˆä»åŒ¹é…è®°å½•ä¸­è·å–ï¼‰"""
    conn = sqlite3.connect(config.DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    # ç›´æ¥ä»åŒ¹é…è®°å½• + top_performers è·å–
    cursor.execute('''
        SELECT m.id, m.news_content, m.keywords, t.token_symbol
        FROM match_records m
        JOIN top_performers t ON m.id = t.match_id
        WHERE t.performance_rank = 1
        ORDER BY m.created_at DESC
        LIMIT 20
    ''')

    results = []
    for r in cursor.fetchall():
        results.append({
            'id': r['id'],
            'tweet_content': r['news_content'],
            'keywords': json.loads(r['keywords']),
            'best_token': r['token_symbol']
        })

    conn.close()
    return jsonify(results)


@app.route('/best_practices', methods=['POST'])
def add_best_practice():
    """æ‰‹åŠ¨æ·»åŠ åŒ¹é…è®°å½•ï¼ˆæ¨æ–‡+ä»£å¸ï¼‰"""
    data = request.json
    tweet_content = data.get('tweet_content', '')
    keywords = data.get('keywords', [])
    best_token = data.get('best_token', '')

    if not tweet_content or not keywords or not best_token:
        return jsonify({'success': False, 'error': 'ç¼ºå°‘å¿…è¦å­—æ®µ'}), 400

    conn = sqlite3.connect(config.DB_PATH)
    cursor = conn.cursor()

    # 1. æ’å…¥ match_records
    cursor.execute('''
        INSERT INTO match_records (news_time, news_author, news_author_name, news_avatar,
            news_type, news_content, news_images, news_videos,
            ref_author, ref_author_name, ref_avatar, ref_content, ref_images, keywords)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    ''', (
        int(time.time()), 'manual', 'æ‰‹åŠ¨æ·»åŠ ', '',
        'manual', tweet_content, '[]', '[]',
        '', '', '', '', '[]', json.dumps(keywords, ensure_ascii=False)
    ))
    match_id = cursor.lastrowid

    # 2. æ’å…¥ top_performers
    cursor.execute('''
        INSERT INTO top_performers (match_id, performance_rank, token_address, token_symbol,
            token_name, chain, initial_market_cap, final_market_cap, market_cap_change_pct, performance_score)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    ''', (match_id, 1, f'manual_{match_id}', best_token, best_token, 'MANUAL', 0, 0, 0, 0))

    conn.commit()
    conn.close()

    return jsonify({'success': True, 'id': match_id})


@app.route('/best_practices/<int:practice_id>', methods=['DELETE'])
def delete_best_practice(practice_id):
    """åˆ é™¤åŒ¹é…è®°å½•"""
    conn = sqlite3.connect(config.DB_PATH)
    cursor = conn.cursor()
    cursor.execute('DELETE FROM top_performers WHERE match_id = ?', (practice_id,))
    cursor.execute('DELETE FROM matched_tokens WHERE match_id = ?', (practice_id,))
    cursor.execute('DELETE FROM match_records WHERE id = ?', (practice_id,))
    conn.commit()
    conn.close()
    return jsonify({'success': True})


@app.route('/delete_records', methods=['POST'])
def delete_records():
    """ç§»é™¤æœ€ä½³å®è·µæ ‡è®°ï¼ˆis_best è®¾ä¸º 0ï¼‰"""
    data = request.json
    ids = data.get('ids', [])

    if not ids:
        return jsonify({'success': False, 'error': 'æœªé€‰æ‹©è®°å½•'}), 400

    conn = sqlite3.connect(config.DB_PATH)
    cursor = conn.cursor()

    removed = 0
    for record_id in ids:
        try:
            # æŠŠè¯¥è®°å½•ä¸‹æ‰€æœ‰ä»£å¸çš„ is_best è®¾ä¸º 0
            cursor.execute('UPDATE matched_tokens SET is_best = 0 WHERE match_id = ?', (record_id,))
            # åˆ é™¤ top_performers è®°å½•
            cursor.execute('DELETE FROM top_performers WHERE match_id = ?', (record_id,))
            removed += 1
        except Exception as e:
            print(f"[ç§»é™¤æœ€ä½³] è®°å½• {record_id} å¤±è´¥: {e}", flush=True)

    conn.commit()
    conn.close()

    return jsonify({'success': True, 'removed': removed})


def insert_demo_data():
    """æ’å…¥é¢„åˆ¶æ ·ä¾‹æ•°æ®"""
    conn = sqlite3.connect(config.DB_PATH)
    cursor = conn.cursor()

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
    cursor.execute('SELECT COUNT(*) FROM match_records')
    if cursor.fetchone()[0] > 0:
        conn.close()
        return

    print("[DB] æ’å…¥é¢„åˆ¶æ ·ä¾‹æ•°æ®...", flush=True)

    # æ ·ä¾‹1: å¸å®‰ä¸€å§æ¨æ–‡
    demo_news_1 = {
        'time': int(time.time()) - 300,
        'author': 'heyibinance',
        'authorName': 'Yi He',
        'avatar': '',
        'type': 'newTweet',
        'content': 'å”‰å‘€å‘€å‘€å‘€ï¼Œæ„Ÿè°¢æˆ‘Jasonæ€»ï¼Œä½ å¯å¤ªæ€§æƒ…å¤ªé€šé€äº†ï¼Œç®€ç›´å°±æ˜¯å¸å®‰æ€ç»´ï¼Œç¥ä½ æŒæœ‰BNBå¼€å¸å®‰æ±½è½¦ï¼Œä½å¸å®‰å°åŒºï¼Œäº«å¸å®‰äººç”ŸğŸ™',
        'images': [],
        'videos': [],
        'refAuthor': '',
        'refAuthorName': '',
        'refAvatar': '',
        'refContent': '',
        'refImages': []
    }
    keywords_1 = ['å¸å®‰æ€ç»´', 'bnb', 'å¸å®‰æ±½è½¦', 'å¸å®‰å°åŒº', 'å¸å®‰äººç”Ÿ']
    tokens_1 = [{
        'tokenAddress': '0xdemo1234567890',
        'tokenSymbol': 'å¸å®‰äººç”Ÿ',
        'tokenName': 'å¸å®‰äººç”Ÿ',
        'chain': 'BSC',
        'price': '0.00001',
        'marketCap': 5000,
        'holders': 50,
        '_match_score': 5.0,
        '_matched_keyword': 'å¸å®‰äººç”Ÿ',
        '_match_type': 'å®Œå…¨åŒ¹é…symbol',
        '_final_score': 250
    }]

    # æ ·ä¾‹2: Elon Musk
    demo_news_2 = {
        'time': int(time.time()) - 600,
        'author': 'elonmusk',
        'authorName': 'Elon Musk',
        'avatar': '',
        'type': 'newTweet',
        'content': 'DOGE to the moon! ğŸš€',
        'images': [],
        'videos': [],
        'refAuthor': '',
        'refAuthorName': '',
        'refAvatar': '',
        'refContent': '',
        'refImages': []
    }
    keywords_2 = ['doge', 'moon']
    tokens_2 = [{
        'tokenAddress': '0xdemo0987654321',
        'tokenSymbol': 'DOGE',
        'tokenName': 'Doge',
        'chain': 'BSC',
        'price': '0.00005',
        'marketCap': 15000,
        'holders': 120,
        '_match_score': 5.0,
        '_matched_keyword': 'doge',
        '_match_type': 'å®Œå…¨åŒ¹é…symbol',
        '_final_score': 600
    }]

    # æ’å…¥æ ·ä¾‹
    for news, kws, toks in [(demo_news_1, keywords_1, tokens_1), (demo_news_2, keywords_2, tokens_2)]:
        cursor.execute('''
            INSERT INTO match_records (
                news_time, news_author, news_author_name, news_avatar, news_type,
                news_content, news_images, news_videos,
                ref_author, ref_author_name, ref_avatar, ref_content, ref_images,
                keywords
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            news['time'], news['author'], news['authorName'], news['avatar'], news['type'],
            news['content'], json.dumps(news['images']), json.dumps(news['videos']),
            news['refAuthor'], news['refAuthorName'], news['refAvatar'],
            news['refContent'], json.dumps(news['refImages']),
            json.dumps(kws, ensure_ascii=False)
        ))
        match_id = cursor.lastrowid

        for rank, token in enumerate(toks, 1):
            cursor.execute('''
                INSERT INTO matched_tokens
                (match_id, rank, token_address, token_symbol, token_name, chain,
                 initial_price, initial_market_cap, initial_holders,
                 match_score, match_keyword, match_type, final_score)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                match_id, rank, token['tokenAddress'], token['tokenSymbol'],
                token['tokenName'], token['chain'], token['price'],
                token['marketCap'], token['holders'], token['_match_score'],
                token['_matched_keyword'], token['_match_type'], token['_final_score']
            ))

        # æ’å…¥æœ€ä½³ä»£å¸è®°å½•
        for rank, token in enumerate(toks, 1):
            cursor.execute('''
                INSERT INTO top_performers
                (match_id, performance_rank, token_address, token_symbol, token_name, chain,
                 initial_market_cap, final_market_cap, market_cap_change_pct, performance_score)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                match_id, rank, token['tokenAddress'], token['tokenSymbol'],
                token['tokenName'], token['chain'], token['marketCap'],
                token['marketCap'] * 1.5, 50.0, 25.0
            ))

    conn.commit()
    conn.close()
    print("[DB] é¢„åˆ¶æ ·ä¾‹æ•°æ®æ’å…¥å®Œæˆ", flush=True)


if __name__ == "__main__":
    port = config.get_port('tracker')
    print(f"ä»£å¸è·Ÿè¸ªæœåŠ¡å¯åŠ¨: http://127.0.0.1:{port}", flush=True)

    init_db()
    insert_demo_data()

    tracker_thread = threading.Thread(target=tracking_worker, daemon=True)
    tracker_thread.start()

    app.run(host='0.0.0.0', port=port, debug=False, threaded=True)
